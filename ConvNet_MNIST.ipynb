{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded\n"
     ]
    }
   ],
   "source": [
    "transform=transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                             ])\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, \n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = ('Zero', 'One', 'Two', 'Three',\n",
    "           'Four', 'Five', 'Six', 'Seven', 'Eight', 'Nine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.train_data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.train_labels.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 28, 28])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5 # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    6     1     3     7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB2CAYAAADY3GjsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6CIiCaEKXUQkIf4f8h/3TmPcNUkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f64c611c350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s'%labels[j] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net (\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear (256 -> 120)\n",
       "  (fc2): Linear (120 -> 84)\n",
       "  (fc3): Linear (84 -> 10)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool  = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1   = nn.Linear(16*4*4, 120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16*4*4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # use a Classification Cross-Entropy loss\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "FloatSpatialConvolutionMM_updateOutput received an invalid combination of arguments - got (int, torch.FloatTensor, torch.FloatTensor, torch.cuda.FloatTensor, torch.cuda.FloatTensor, torch.FloatTensor, torch.FloatTensor, long, long, int, int, int, int), but expected (int state, torch.FloatTensor input, torch.FloatTensor output, torch.FloatTensor weight, [torch.FloatTensor bias or None], torch.FloatTensor finput, torch.FloatTensor fgradInput, int kW, int kH, int dW, int dH, int padW, int padH)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2ed11e46e641>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-4a280cbee99d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/conv.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 235\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/functional.pyc\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, weight, bias, stride, padding, dilation, groups)\u001b[0m\n\u001b[1;32m     35\u001b[0m     f = ConvNd(_pair(stride), _pair(padding), _pair(dilation), False,\n\u001b[1;32m     36\u001b[0m                _pair(0), groups)\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/_functions/conv.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_view4d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_view3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/_functions/conv.pyc\u001b[0m in \u001b[0;36m_update_output\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bufs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'update_output'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_grad_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/_functions/conv.pyc\u001b[0m in \u001b[0;36m_thnn\u001b[0;34m(self, fn_name, input, weight, *args)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mimpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_thnn_convs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthnn_class_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bufs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/_functions/conv.pyc\u001b[0m in \u001b[0;36mcall_update_output\u001b[0;34m(self, bufs, input, weight, bias)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         getattr(backend, fn.name)(backend.library_state, input, output, weight,\n\u001b[0;32m--> 219\u001b[0;31m                                   bias, *args)\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_update_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: FloatSpatialConvolutionMM_updateOutput received an invalid combination of arguments - got (int, torch.FloatTensor, torch.FloatTensor, torch.cuda.FloatTensor, torch.cuda.FloatTensor, torch.FloatTensor, torch.FloatTensor, long, long, int, int, int, int), but expected (int state, torch.FloatTensor input, torch.FloatTensor output, torch.FloatTensor weight, [torch.FloatTensor bias or None], torch.FloatTensor finput, torch.FloatTensor fgradInput, int kW, int kH, int dW, int dH, int padW, int padH)"
     ]
    }
   ],
   "source": [
    "for epoch in range(2): # loop over the dataset multiple times\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        \n",
    "        inputs.cuda()\n",
    "        labels.cuda()\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 2000 == 1999: # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch+1, i+1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded\n"
     ]
    }
   ],
   "source": [
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, \n",
    "                                          shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('GroundTruth: ', 'Seven   Two   One  Zero')\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB2CAYAAADY3GjsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEQ1JREFUeJzt3XuMVGWax/HvI4rCmCgIIioIssgGr2irLCOGqGNQUcQb\nQ9QlxogaL8w66uI1rkYdjXF3NQjBkR0vE8YLqKgosgiCCbDQgoPcVFwFFARdbyhewGf/qDovb0OV\nXd116zr9+ySdfuqtU3WeU6f67XPe8573NXdHRERq3y7VTkBEREpDFbqISEqoQhcRSQlV6CIiKaEK\nXUQkJVShi4ikhCp0EZGUKKpCN7PBZrbKzD4wszGlSkpERJrOmntjkZm1Ad4DfgesAxYCI9x9eenS\nExGRQu1axGuPAz5w9w8BzOxvwFAgb4XeqVMn79GjRxGrFBFpferr6z93986NLVdMhX4AsDZ6vA44\nfseFzGwUMAqge/fuLFq0qIhVioi0Pmb2cSHLlf2iqLtPcPc6d6/r3LnRfzAiItJMxVTonwDdoscH\nZstERKQKiqnQFwK9zaynmbUFfg9MLU1aIiLSVM1uQ3f3rWZ2NTAdaANMdPdlJctMRESapJiLorj7\nNGBasUmYWbFv0Srl6nKqz7J58nXf1efZPPo8q0N3ioqIpIQqdBGRlFCFLiKSEqrQRURSQhW6iEhK\nqEIXEUkJVegiIilRVD90keuvvz7E7dq1C/ERRxwR4vPOO2+n140bNy7E8+bNC/GTTz5Z6hRFWg0d\noYuIpIQqdBGRlFCTizTZ008/HeJczSk7+uWXX3Yqu/zyy0N8yimnhHj27NkhXrs2Hm5fCtW7d+8Q\nr1q1CoDRo0eHsocffrjiObUk7du3D/EDDzwQ4vg7WV9fDzT8fq9Zs6YC2RVHR+giIimhCl1EJCXU\n5CIFS5paCmlmWblyZYinT58OwMEHHxzKzjzzzBD36tUrxBdffHGI77nnnuYn24odffTRIU6auz75\nRHPPJPbff/8QX3bZZSGOmwaPOeYYoOH3dOzYsRXIrjg6QhcRSQkdocuvSo5UAIYNG7bT88uWbZ/T\nJD6a+fzzz0P83XffAbDbbruFsgULFoT4yCOPDHHHjh2LzFiOOuqoECef/ZQpU6qVTovRqVMnAB5/\n/PEqZ1I+OkIXEUkJVegiIimRiiaX+CJdfJHj008/DfEPP/wAwFNPPRXKNmzYEOLVq1eXM8WaFV9A\nSqYPi5tZTj311BDHn2cuN9xwQ4j79u2bc5lXXnmlWXm2docddliIr7nmmhA/8cQT1Uinxbj22mtD\nfPbZZwNw3HHHFfz6E088McS77LL9+HfJkiUhnjt3bjEpllSjR+hmNtHMNprZu1FZRzObYWbvZ393\nKG+aIiLSmEKaXP4CDN6hbAww0917AzOzj0VEpIos3+zcDRYy6wG87O6HZR+vAga5+3oz6wrMdvc+\njb1PXV2dL1q0KNf7NzHthj788MMQ9+jRo+DXffvttyGOmxFKad26dSG+7777QpzcWlyMXPuunLOq\nd+/eHWj4uX355ZcFv/6dd94JcdxEEIuHAZg1a1ZTU2y2Wp+lPm52fOaZZ0I8aNAgAObMmVPRfFrK\n57lt27YQ5xqCIp+keSXfaz7++OMQX3DBBSF+++23m5pioerdva6xhZp7UbSLu6/PxhuALvkWNLNR\nZrbIzBZt2rSpmasTEZHGFN3LxTP/ivMe5rv7BHevc/e6zp07F7s6ERHJo7m9XD4zs65Rk8vGUibV\nVHHPlvgmleXLl4c46VXRr1+/UJacjgL0798/xPEof926dfvVdW/dujXE8RlI165dd1o2Hq2tFE0u\nldbc0eaS3i2HHHJIzufjm4zmz5/frHW0djfeeGOI4+aAXE2caTdt2rQQxz1TmuKLL74AYPPmzaHs\noIMOCnHPnj1DvHDhwhC3adOmWesrleYeoU8FRmbjkcCLpUlHRESaq5Bui5OAeUAfM1tnZpcCfwJ+\nZ2bvA6dkH4uISBU12uTi7iPyPHVyiXNptpkzZ+aMY6+99tpOZXvvvXeI4xHq4lOoxm5C2LJlS4jf\ne++9ECejDcZjk8S9cdJuyJAhIb7zzjsBaNu2bSjbuHF7K92YMdt7vcafp/y6uAmgrm57B4j4e/j9\n999XNKdqiW8A6tNne4e7uJdKY71cxo8fH+LXX38dgK+++iqUnXzy9irvlltuyfkeV155JdBwztxK\n0q3/IiIpkYpb/5sr/u/7xhtv5Fwm3xF/Lueee26IO3TI3Dy7dOnSUDZp0qSmpliz4iPG+Mg8EU9j\nV+k+0mkRX9SPtZbuwfEZSvx9SkZVzCe+aDx58uQQ33HHHSHOdaYYv27UqFEhjnvv3X///QDsscce\noSye8i/uRFEOOkIXEUkJVegiIinRqptcSiE+3XrkkUdCnPR/TS4IQtNuk69FL7zwQojjURgT8ch/\n+S4qSeEOP/zwnOXJaX/axROmNNbMAvDmm28CMHz48FCW9DcvRHwfxr333hviBx98MMTt27cHGu6D\nF1/c3qu73B0jdIQuIpISqtBFRFJCTS5Fuvrqq0McN78kzStJf/S02m+//UI8YMCAEO++++4hTuYX\nveuuu0JZMtelNE08RMUll1wS4sWLF4c46UMtDYc+SD6vpjSz5BM3o1x44YUhPvbYY4t+72LoCF1E\nJCVUoYuIpISaXJohblqIb1uPDR06FCjfxBktxZQpU0K8zz775Fwmmce1NQ19UC7xBCDxsBLx0BY/\n/vhjRXNqCfKNqnj88ceXZX3xRB3xunPlEfd0u+iii8qST1h/Wd9dREQqRhW6iEhKqMmlGc4444wQ\nxzc3xOO+zJs3r6I5VdJZZ50V4niUytjs2bNDfPvtt5c7pVYjnsAlnrfzueeeq0Y6VXXFFVeEuCnz\nhZZC/DcQT5qT5BHnU8nvv47QRURSQkfoBYpHTxs8eHCIf/rppxDH/4nLPapaNSQX4W6++eZQFp+h\nxJYsWRJi9TkvXpcumXnYBw4cGMpWrVoV4ueff77iOVXbmWeeWfZ1xEMKJNNYQsO/gVziES9//vnn\n0ieWh47QRURSQhW6iEhKqMmlQPGs6vFFkLj/b5ovhAJcf/31QP7bm+PRFnUhtLSS29b33XffUPbq\nq69WK51W49Zbbw3xVVdd1ejyH330EQAjR44MZWvXri15XvkUMkl0NzObZWbLzWyZmY3Olnc0sxlm\n9n72d4fypysiIvkU0uSyFfiju/cF+gNXmVlfYAww0917AzOzj0VEpEoabXJx9/XA+mz8rZmtAA4A\nhgKDsos9DswG/rUsWVZR0uf8tttuC2XffPNNiOPbetPuuuuu+9Xn41NS9WwprXj+zETaJ0yppmnT\npgHQp0+fJr1uxYoVALz11lslz6kQTbooamY9gH7AAqBLtrIH2AB0yfOaUWa2yMwWtZbJa0VEqqHg\nCt3M9gQmA39w92/i5zxzy5rnep27T3D3Onevi8cLFxGR0iqol4uZ7UamMv+ruyfD631mZl3dfb2Z\ndQU2livJSotHsXvooYcAaNOmTShLTscA5s+fX7nEWrj4c2vKzRRff/11iOMbsnbdNfP13GuvvXK+\nrkOH7dfhG2sO2rZtW4jjHktbtmwpOM9qynUTzcsvv1yFTFqOfCMexk477bSdyh599NEQd+3aNefr\nkvdr6pACQ4YMadLypVZILxcDHgNWuPuD0VNTgaRvzkjgxR1fKyIilVPIEfpvgYuBpWaW3M99M/An\n4BkzuxT4GLigPCmKiEghCunl8hZgeZ4+ubTpVE98yjZ9+vQQ9+zZE4DVq1eHsvhmA9lu6dKlzXrd\ns88+G+L169eHOBm/ZPjw4cUltoMNGzaE+O677y7pe5fSCSecEOLks5Dtxo0bF+L7778/5zJxs1Su\n5pPGmlQKaXIZP358o8tUim79FxFJCd36n9WrV68QH3PMMTs9H190a61TqSUXg5Pp9Url/PPPL3jZ\n+KJpvqOnqVOnAg1nfI/NnTu3CdlVz7Bhw0KcXJRfvHhxKIvHnG+NJk+eHOIbbrghxKXsTRd3tU76\nmANcdtllIY7PKqtNR+giIimhCl1EJCVadZNL9+7dQzxjxoycyySnci+99FJFcmrJzjnnHKBhP+58\nE1zEDj30UKCwi5sTJ04McTJyXSw+zV65cmWj71dr2rVrF+LTTz99p+fjqeYqPe1aS7NmzZoQx9+t\nuKlq9OjRRa0jvmg+duzYot6rEnSELiKSEqrQRURSwuKZw8utrq7Oc/U8iG/hraT4dOqmm27KuUwy\nmUN9fX1FcmqKXPuuWp9lrcv3d1DpzzMZ7gBgzpw5Id64MTOyxogRI0JZSx62oKV8nvH8v6NGjQIa\nDqOQ9IgCmDBhQoiTPJctWxbKKjlRRQ717l7X2EI6QhcRSQlV6CIiKdHqernEt1Nfc801VcxEZGfx\njVMDBgyoYibpEM/5G8dppSN0EZGUUIUuIpISra7JZeDAgSHec889cy4Tj6y4efPmsuckIlIKOkIX\nEUmJVneEns8777wT4pNOOinEmlldRGqFjtBFRFJCFbqISEq06lv/a51u/S+dlnKrelro8yw53fov\nItKaqEIXEUmJija5mNkm4Dvg84qttPI6oe2rZWnevjRvG6R7+w5y90YnS61ohQ5gZosKaQuqVdq+\n2pbm7UvztkH6t68QanIREUkJVegiIilRjQp9QuOL1DRtX21L8/aledsg/dvXqIq3oYuISHmoyUVE\nJCUqWqGb2WAzW2VmH5jZmEquu9TMrJuZzTKz5Wa2zMxGZ8s7mtkMM3s/+7tDtXMthpm1MbPFZvZy\n9nFPM1uQ3YdPm1nbaufYXGa2t5k9Z2YrzWyFmf1Tmvafmf1L9rv5rplNMrM9ann/mdlEM9toZu9G\nZTn3l2U8lN3Ov5vZ0dXLvHIqVqGbWRtgLHAa0BcYYWZ9K7X+MtgK/NHd+wL9gauy2zMGmOnuvYGZ\n2ce1bDSwInp8H/Dv7v4PwJfApVXJqjT+E3jN3f8ROJLMdqZi/5nZAcC1QJ27Hwa0AX5Pbe+/vwCD\ndyjLt79OA3pnf0YB4yqUY1VV8gj9OOADd//Q3X8C/gYMreD6S8rd17v729n4WzKVwQFktunx7GKP\nA2dXJ8PimdmBwBnAn7OPDTgJeC67SM1un5ntBZwIPAbg7j+5+1ekaP+RGR67nZntCrQH1lPD+8/d\n5wD/t0Nxvv01FHjCM+YDe5tZ18pkWj2VrNAPANZGj9dly2qemfUA+gELgC7uvj771AagS5XSKoX/\nAG4Efsk+3gf4yt2TmYxreR/2BDYB/5VtUvqzmf2GlOw/d/8EeABYQ6Yi/xqoJz37L5Fvf6W2vvk1\nuihaJDPbE5gM/MHdv4mf80wXoprsRmRmQ4CN7l5f7VzKZFfgaGCcu/cjMyRFg+aVGt9/HcgcpfYE\n9gd+w87NFalSy/urVCpZoX8CdIseH5gtq1lmthuZyvyv7j4lW/xZcmqX/b2xWvkV6bfAWWb2EZnm\nsZPItDnvnT2Fh9reh+uAde6+IPv4OTIVfFr23ynA/7r7Jnf/GZhCZp+mZf8l8u2v1NU3hahkhb4Q\n6J29yt6WzAWaqRVcf0ll25MfA1a4+4PRU1OBkdl4JPBipXMrBXe/yd0PdPceZPbVG+5+ITALOC+7\nWC1v3wZgrZn1yRadDCwnJfuPTFNLfzNrn/2uJtuXiv0Xybe/pgL/nO3t0h/4OmqaSS93r9gPcDrw\nHrAauKWS6y7DtpxA5vTu78CS7M/pZNqZZwLvA/8NdKx2riXY1kHAy9n4YOB/gA+AZ4Hdq51fEdt1\nFLAouw9fADqkaf8B/wasBN4FngR2r+X9B0wicz3gZzJnWJfm21+AkelVtxpYSqa3T9W3odw/ulNU\nRCQldFFURCQlVKGLiKSEKnQRkZRQhS4ikhKq0EVEUkIVuohISqhCFxFJCVXoIiIp8f+0TwaGQzOc\n0QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6ca5fc9310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s'%classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Predicted: ', ' Five Eight Seven  Five')\n"
     ]
    }
   ],
   "source": [
    "outputs = net(Variable(images))\n",
    "\n",
    "# the outputs are energies for the 10 classes. \n",
    "# Higher the energy for a class, the more the network \n",
    "# thinks that the image is of the particular class\n",
    "\n",
    "# So, let's get the index of the highest energy\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s'% classes[predicted[j][0]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 7 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    c = (predicted == labels).squeeze()\n",
    "    for i in range(4):\n",
    "        label = labels[i]\n",
    "        class_correct[label] += c[i]\n",
    "        class_total[label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  Zero :  5 %\n",
      "Accuracy of   One :  0 %\n",
      "Accuracy of   Two :  0 %\n",
      "Accuracy of Three :  0 %\n",
      "Accuracy of  Four :  0 %\n",
      "Accuracy of  Five : 40 %\n",
      "Accuracy of   Six :  0 %\n",
      "Accuracy of Seven :  4 %\n",
      "Accuracy of Eight : 30 %\n",
      "Accuracy of  Nine :  0 %\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
